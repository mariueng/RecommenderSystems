{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24a1d360-f796-4a4e-ac66-56ed6784f219",
   "metadata": {},
   "source": [
    "# TDT4215 Group Project: Recommender System for News Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b69b76-a609-4790-9cf8-eea607e49357",
   "metadata": {},
   "source": [
    "This notebook provides group project details for course TDT4215 Recommender Systems. It also contains information about the dataset students are expected to use, and runs some example code to demonstrate how a basic recommender system might look like. The notebook is intended as a living document during the duration of the semester to accommodate any changes or clarifications. All updates will be listed at the end, along with the date, in the effort to keep all relevant information in one place and avoid confusion.\n",
    "\n",
    "The original authors of the project are Lemei Zhang and Peng Liu, who are reachable via their NTNU email addresses, though they are not active course staff, so you probably shouldn't bother them üôÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccb7c74-5582-4fe0-a75f-559b70081c27",
   "metadata": {},
   "source": [
    "## 1. General requirements and learning outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a7d2c-25ef-4800-b1ff-fffe27b807c7",
   "metadata": {},
   "source": [
    "The goal of the student project is to apply the theoretical knowledge gained from lectures to solve a practical problem of building a recommender system for a newspaper website. Online news is one of the most important and popular ways for people to get informed every day. The task in this project is to filter the most useful and relevant news for a specific user. Students are expected to approach solving this problem through team work, experimentation, and analytical thinking within a limited time, adhering to a schedule outlined in a later section.\n",
    "\n",
    "The development of a recommender system must be done in groups of 2 to 4 students. Each student group will use the same dataset, collected from Adresseavisen portal, described in more detail below. Each group is free to choose their own tools and develop their own methods in order to get the best results. The only constraint is using the Adressa dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a368b3e-05e5-459b-97e6-546c4f10d6ec",
   "metadata": {},
   "source": [
    "## 2. Important dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9cf41a-5105-4a80-9300-0f13c52ecd54",
   "metadata": {},
   "source": [
    "| Date | Description |\n",
    "| :------| :-----------|\n",
    "| **January 24th** | Group project kick-off and start of group registrations |\n",
    "| **February 8th** | Group formation deadline |\n",
    "| **April 15th** | Report submission deadline |\n",
    "| **April 22nd** | Project presentations |\n",
    "\n",
    "The course staff is currently considering organization of mid-term project presentation to check on the groups' progress. You will be notified if we make such a decision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4220244a-3b89-471a-ac97-51a635e5a6d2",
   "metadata": {},
   "source": [
    "## 3. Deliverables and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0d17b4-0758-40ad-ba46-6b6f48dda361",
   "metadata": {},
   "source": [
    "The group work will be evaluated based on two deliverables: the project report and the project presentation. Both are equally important. The project itself will not be graded. It is only possible to pass or fail. Passing the group project is necessary for taking the exam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f016aaf5-1ee1-4e50-852b-7f45a94f14d9",
   "metadata": {},
   "source": [
    "### 3.1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a37adb3-7c6a-44c6-96bd-085bdb250e12",
   "metadata": {},
   "source": [
    "Your report should include the following:\n",
    "- Motivation for your project topic\n",
    "- A ***brief*** overview of existing news recommender algorithms and approaches (you don't have to research state-of-the-art, just provide the background relevant for the approaches you utilized, and how they fit into the theoretical concepts from the lectures).\n",
    "- At least two *reasonably different* recommendation approaches, one of which can be categorized as collaborative filtering. All recommendations have to be **personalized**, but they can include non-personalized considerations as well.\n",
    "- Explain the derived recommender models and the architecture of the implemented recommender system.\n",
    "- The evaluation results with multiple (at least two) *reasonably different* performance indicators. See below for some evaluation metrics you may choose to use.\n",
    "- Visualizations to help convey your main points where appropriate.\n",
    "- Discussion of your obtained results.\n",
    "- Conclusion and any additional remarks related to your project that you find interesting.\n",
    "\n",
    "Your report has to be submitted with the *runnable* implementation of your system. This means that we can easily run your submitted code as long as we add the Adressa dataset (you don't have to submit the datasets we provide here). If we try to run it and can't, we will ask you for clarification via email. If we still can't run it after your clarification, you will fail the project. Please make sure that you don't submit buggy code.\n",
    "\n",
    "The results have to be *reproducible*, meaning that we can obtain the similar, not necessarily identical, results by running your code to the ones reported. There is no reason to not report the results you obtain with your implementation, since there are no minimum requirements for the evaluation indicators.\n",
    "\n",
    "The implementation can be in any programming language you choose. If the course staff has any issues with understanding your implementation, we will ask you for clarification with same conditions as above. For everyone's sake, try to keep your code readable.\n",
    "\n",
    "Make sure to include all your decisions in the report. Why you chose to go for a particular method or evaluation indicator over others, etc. The report should not exceed 15 pages with all appendices, tables, and visualizations. You can find some example reports on Blackboard. They are not a template (in part because they don't conform to the page limit), only some help to get you started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4d38e8-24cc-4a8b-9d0d-4b7e7d4e5b98",
   "metadata": {},
   "source": [
    "### 3.2 Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd5b169-4116-4311-845f-51a51b44eb14",
   "metadata": {},
   "source": [
    "The project presentation will be the opportunity for the student groups to show their understanding of their implemented approaches and design choices. On the other hand, it will be opportunity for the course staff to make sure all the group members are familiar with the ideas necessary for project completion. Presentation should take between 10 to 15 minutes for each group. After each presentations, course staff will ask some questions for around 5 to 10 minutes. All group members are expected to attend and participate in the question answering part. You don't need to have an answer for each question, but you *should* be able to understand what you're being asked.\n",
    "\n",
    "In case of a large number of student groups, we might extend project presentations to additional date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeac724-8001-4949-91ca-7fcb44e81ca5",
   "metadata": {},
   "source": [
    "## 4. Adressa dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27f2b26-7f69-4096-be54-d5ce0f1616a1",
   "metadata": {},
   "source": [
    "The project dataset is a refined version of the Adressa dataset published by the SmartMedia group at NTNU in partnership with the local newspaper Adresseavisen in Trondheim. This dataset includes anonymized user data from local digital newspaper from 01.01.2017 to 31. 03. 2017 (3 months in total). We filter 1000 most active users from the original dataset, and select 9 attributes that we think most relevant for the project. The dataset is around 85Mb in a compressed size. Due to licensing reasons, we can't include the archive in this repository. You can download it from Blackboard's course page. In case you want to know more than is available here, the information about the original dataset and its documentation are available on http://reclab.idi.ntnu.no/dataset.\n",
    "\n",
    "In case you want to work with article contents, and not just clickstream logs available in the data described in this section, full articles (in Norwegian) from the newspaper are also available. Unfortunately, due to licensing, they have to be requested on individual basis by student groups. To get article contents, it's enough for one group member to request them by emailing the responsible TA (Mateja)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a99960-c8d9-4eec-bdd7-8c2f8b4f9811",
   "metadata": {},
   "source": [
    "### 4.1 Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05973e0d-0b0e-4b8d-b544-ffad22a43a06",
   "metadata": {},
   "source": [
    "The data in the refined dataset consists of clicking events (clickstream) in JSON format, organized by dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88dcedd7-c415-4628-9136-049c0c2a6d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20170321', '20170113', '20170114', '20170326', '20170319', '20170122', '20170310', '20170317', '20170125', '20170328', '20170124', '20170316', '20170329', '20170311', '20170123', '20170327', '20170115', '20170318', '20170112', '20170320', '20170208', '20170201', '20170206', '20170207', '20170209', '20170213', '20170214', '20170222', '20170225', '20170224', '20170223', '20170215', '20170212', '20170302', '20170130', '20170108', '20170305', '20170101', '20170106', '20170107', '20170109', '20170304', '20170131', '20170303', '20170325', '20170117', '20170128', '20170110', '20170322', '20170126', '20170314', '20170119', '20170313', '20170121', '20170120', '20170312', '20170315', '20170127', '20170118', '20170323', '20170111', '20170116', '20170324', '20170129', '20170205', '20170202', '20170203', '20170204', '20170228', '20170217', '20170210', '20170219', '20170226', '20170221', '20170220', '20170218', '20170227', '20170211', '20170216', '20170306', '20170301', '20170308', '20170105', '20170330', '20170102', '20170103', '20170331', '20170309', '20170104', '20170307']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "DATA_FOLDER = 'active1000'\n",
    "files = os.listdir(DATA_FOLDER)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446eea1b-4368-46de-bc29-b10e55fde79c",
   "metadata": {},
   "source": [
    "In Python, you can use *json* package to read these events. Let's take a closer look at a single click event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "009ca1b1-2735-4c8a-b5db-a177c5d9af04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"eventId\": 304742641,\n",
      "    \"category\": null,\n",
      "    \"activeTime\": 18,\n",
      "    \"title\": \"Bil kj\\u00f8rte av veien i Trondheim\",\n",
      "    \"url\": \"http://adressa.no/nyheter/trondheim/2017/01/21/bil-har-kj%c3%b8rt-av-veien-i-trondheim-14096618.ece\",\n",
      "    \"userId\": \"cx:172hiwprmaxp6t900xbxm2tin:35r8k9abzv9u5\",\n",
      "    \"publishtime\": null,\n",
      "    \"time\": 1485039620,\n",
      "    \"documentId\": \"1b00089faaa14baf2765794f567a9b83dc2d1a93\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "ARBITRARY_INDEX = 5\n",
    "filepath = os.path.join(DATA_FOLDER, files[ARBITRARY_INDEX])\n",
    "\n",
    "# one way to load all events into memory\n",
    "events = []\n",
    "for line in open(filepath):\n",
    "    events.append(json.loads(line.strip()))\n",
    "\n",
    "print(json.dumps(events[ARBITRARY_INDEX], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a50b914-92c3-49f1-8adf-2188e13d95a1",
   "metadata": {},
   "source": [
    "We can see there are 9 attributes in one event: *activeTime*, *category*, *documentId*, *eventId*, *publishtime*, *time*, *title*, *url*, and *userId*. Note that not all attributes have values. If some attributes have no value, there will be a None type instead, denoted above by *null* value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9e85fe-ab5a-4688-885a-9673c99afc71",
   "metadata": {},
   "source": [
    "### 4.2 Basic statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff5c2aa-922d-43a9-81aa-4c28103f9d57",
   "metadata": {},
   "source": [
    "Let's look at some basic statistics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3c736c4-f24d-422b-926d-9ff242c1908e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics of the dataset...\n",
      "Total number of events (front page incl.): 2207608\n",
      "Total number of events (without front page): 788931\n",
      "Total number of documents: 20344\n",
      "Sparsity: 3.878%\n",
      "Total number of events (drop duplicates): 679355\n",
      "Sparsity (drop duplicates): 3.339%\n",
      "\n",
      "Describe by user:\n",
      "            counts\n",
      "count  1000.000000\n",
      "mean    679.355000\n",
      "std     333.619737\n",
      "min      59.000000\n",
      "25%     506.750000\n",
      "50%     639.500000\n",
      "75%     797.500000\n",
      "max    7958.000000\n"
     ]
    }
   ],
   "source": [
    "import project_example as pe\n",
    "\n",
    "df=pe.load_data(\"active1000\")\n",
    "print(\"\\nBasic statistics of the dataset...\")\n",
    "pe.statistics(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4291b54e-6860-4f8a-823e-a3755cbd65d8",
   "metadata": {},
   "source": [
    "In the output above, events are user clicks, and documents are news articles.\n",
    "\n",
    "\"Front page event\" is user opening a [front page](https://www.adressa.no/) of the newspaper.\n",
    "\n",
    "Duplicates are repeated user-document pairs, which occur for example when user refreshes an article. The lower statistics block is with duplicates dropped. So for example, by slightly changing the underlying example code, you can easily see that the maximum events per user without dropping duplicates is 7960, while minimum is 181, and average number of events per user is 788.931 (up from 679.355).\n",
    "\n",
    "Sparsity being 3.878% means that out of all possible user-ratings for each published article, 3.878% have a value. Note that, although we fill the missing values with 0, we should not assume that these values are truly zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2e954c-367a-44c0-b7a8-491b2174060e",
   "metadata": {},
   "source": [
    "## 5. Example recommenders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0294ba-cffe-45b3-ae0a-9880042c23a8",
   "metadata": {},
   "source": [
    "In the scripts located in the same repository as this notebook, we offer two recommendation examples. By themselves, these wouldn't be enough for passing the project, since they don't satisfy the requirements above. You are encouraged to come up with your own approaches. If you, however, decide to use the example code as your foundation, be aware that you will have to make sufficient improvements in the design of both systems in order to pass, aside from satisfying the missing requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeda4fc-d6fd-4bea-b77c-c2695be65e29",
   "metadata": {},
   "source": [
    "### 5.1 Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61102c22-97d5-4e72-be32-dbe8971c7677",
   "metadata": {},
   "source": [
    "Collaborative Filtering (CF) is a widely adopted category of recommendation algorithms. The fundamental assumption of CF is that if user X and Y rate n items similarly, or have similar behaviours (such as buying, rating, clicking, listening), and hence will rate or act on other items similarly.\n",
    "\n",
    "There are many kinds of CF and CF extended algorithms online nowadays. In this notebook, we introduce the Explicit Matrix Factorization (MF) as an example. MF is based on the assumptions of:\n",
    "1. each user can be described by k features;\n",
    "2. each item can be described by k attributes;\n",
    "3. predicted value of rating or clicking probability of an item can be represented by the summation of each multiplication of user feature value and item feature value.\n",
    "\n",
    "We will not elaborate MF here. Students can look up their own sources for Explicit Matrix Factorization, such as this one [here](https://www.ethanrosenthal.com/2016/01/09/explicit-matrix-factorization-sgd-als/), on which our code implementation of MF is based upon. Difference is that we assume the ratings of clicked items are 1, and otherwise 0 in user-item matrix.\n",
    "\n",
    "Before MF, we split our data into training and test sets by randomly choosing a fraction of ratings per user from the whole dataset in *function train_test_split(ratings, fraction)*. Think about the validity of this decision.\n",
    "\n",
    "The evaluation of MF is according to MSE, which is explained later on. The output results of each iteration are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62b35269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading:\n",
      "[ True False False ... False False False]\n",
      "[   1    1    1 ... 1000 1000 1000]\n",
      "Dataframes: \n",
      "Original df: \n",
      "      eventId              category  activeTime  \\\n",
      "0  1500434790  100sport|vintersport        17.0   \n",
      "1   161256052  100sport|vintersport         NaN   \n",
      "2   969112529  100sport|vintersport         NaN   \n",
      "3  2032510999  100sport|vintersport       110.0   \n",
      "4  2036417609  100sport|vintersport         NaN   \n",
      "\n",
      "                                               title  \\\n",
      "0  Norges landslagssjef ville ha russisk leder ut...   \n",
      "1  Norges landslagssjef ville ha russisk leder ut...   \n",
      "2  Norges landslagssjef ville ha russisk leder ut...   \n",
      "3  Norges landslagssjef ville ha russisk leder ut...   \n",
      "4  Norges landslagssjef ville ha russisk leder ut...   \n",
      "\n",
      "                                                 url  \\\n",
      "0  http://adressa.no/100sport/langrenn_old/norges...   \n",
      "1  http://adressa.no/100sport/langrenn_old/norges...   \n",
      "2  http://adressa.no/100sport/langrenn_old/norges...   \n",
      "3  http://adressa.no/100sport/langrenn_old/norges...   \n",
      "4  http://adressa.no/100sport/langrenn_old/norges...   \n",
      "\n",
      "                                        userId               publishtime  \\\n",
      "0  cx:10k2wzm1b3jsk2y5ym1utnjo97:2kefzqaxe9jx7  2017-01-01T17:01:11.000Z   \n",
      "1       cx:1323088975693404397604:wi004nwg1lgv  2017-01-01T17:01:11.000Z   \n",
      "2     cx:13248361004781723078120:2wmidk0ara9mw  2017-01-01T17:01:11.000Z   \n",
      "3      cx:1325622642378828560344:30ntt9pj2p3ss  2017-01-01T17:01:11.000Z   \n",
      "4      cx:1351161220132407421422:103o91wtrkqso  2017-01-01T17:01:11.000Z   \n",
      "\n",
      "         time                                documentId  uid  tid  \n",
      "0  1483293374  70a19fd7c9f6827feb3eb4f3df95121664491fa7    1    1  \n",
      "1  1483294671  70a19fd7c9f6827feb3eb4f3df95121664491fa7   14    1  \n",
      "2  1483305285  70a19fd7c9f6827feb3eb4f3df95121664491fa7   20    1  \n",
      "3  1483291064  70a19fd7c9f6827feb3eb4f3df95121664491fa7   21    1  \n",
      "4  1483302979  70a19fd7c9f6827feb3eb4f3df95121664491fa7   45    1  \n",
      "-------------------------------------\n",
      "Extended df: \n",
      "   uid  tid\n",
      "0    1    1\n",
      "1   14    1\n",
      "2   20    1\n",
      "3   21    1\n",
      "4   45    1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 1., 1.],\n",
       "       [1., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe.load_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "078f283b-ac02-4b59-890b-96b86970ff92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendation based on MF...\n",
      "loading:\n",
      "[ True False False ... False False False]\n",
      "[   1    1    1 ... 1000 1000 1000]\n",
      "Dataframes: \n",
      "Original df: \n",
      "      eventId              category  activeTime  \\\n",
      "0  1500434790  100sport|vintersport        17.0   \n",
      "1   161256052  100sport|vintersport         NaN   \n",
      "2   969112529  100sport|vintersport         NaN   \n",
      "3  2032510999  100sport|vintersport       110.0   \n",
      "4  2036417609  100sport|vintersport         NaN   \n",
      "\n",
      "                                               title  \\\n",
      "0  Norges landslagssjef ville ha russisk leder ut...   \n",
      "1  Norges landslagssjef ville ha russisk leder ut...   \n",
      "2  Norges landslagssjef ville ha russisk leder ut...   \n",
      "3  Norges landslagssjef ville ha russisk leder ut...   \n",
      "4  Norges landslagssjef ville ha russisk leder ut...   \n",
      "\n",
      "                                                 url  \\\n",
      "0  http://adressa.no/100sport/langrenn_old/norges...   \n",
      "1  http://adressa.no/100sport/langrenn_old/norges...   \n",
      "2  http://adressa.no/100sport/langrenn_old/norges...   \n",
      "3  http://adressa.no/100sport/langrenn_old/norges...   \n",
      "4  http://adressa.no/100sport/langrenn_old/norges...   \n",
      "\n",
      "                                        userId               publishtime  \\\n",
      "0  cx:10k2wzm1b3jsk2y5ym1utnjo97:2kefzqaxe9jx7  2017-01-01T17:01:11.000Z   \n",
      "1       cx:1323088975693404397604:wi004nwg1lgv  2017-01-01T17:01:11.000Z   \n",
      "2     cx:13248361004781723078120:2wmidk0ara9mw  2017-01-01T17:01:11.000Z   \n",
      "3      cx:1325622642378828560344:30ntt9pj2p3ss  2017-01-01T17:01:11.000Z   \n",
      "4      cx:1351161220132407421422:103o91wtrkqso  2017-01-01T17:01:11.000Z   \n",
      "\n",
      "         time                                documentId  uid  tid  \n",
      "0  1483293374  70a19fd7c9f6827feb3eb4f3df95121664491fa7    1    1  \n",
      "1  1483294671  70a19fd7c9f6827feb3eb4f3df95121664491fa7   14    1  \n",
      "2  1483305285  70a19fd7c9f6827feb3eb4f3df95121664491fa7   20    1  \n",
      "3  1483291064  70a19fd7c9f6827feb3eb4f3df95121664491fa7   21    1  \n",
      "4  1483302979  70a19fd7c9f6827feb3eb4f3df95121664491fa7   45    1  \n",
      "-------------------------------------\n",
      "Extended df: \n",
      "   uid  tid\n",
      "0    1    1\n",
      "1   14    1\n",
      "2   20    1\n",
      "3   21    1\n",
      "4   45    1\n",
      "Iteration: 1\n",
      "Train mse: 0.6013352110905462\n",
      "Test mse: 0.689084981717808\n",
      "Iteration: 2\n",
      "Train mse: 0.5353848589587702\n",
      "Test mse: 0.6429355531131516\n",
      "Iteration: 5\n",
      "Train mse: 0.5131933650670942\n",
      "Test mse: 0.6286072818936076\n",
      "Iteration: 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mariu/dev/school/TDT4215/tdt4215-2022/project_description.ipynb Cell 30'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mariu/dev/school/TDT4215/tdt4215-2022/project_description.ipynb#ch0000028?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mRecommendation based on MF...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mariu/dev/school/TDT4215/tdt4215-2022/project_description.ipynb#ch0000028?line=1'>2</a>\u001b[0m pe\u001b[39m.\u001b[39;49mcollaborative_filtering(df)\n",
      "File \u001b[0;32m~/dev/school/TDT4215/tdt4215-2022/project_example.py:195\u001b[0m, in \u001b[0;36mcollaborative_filtering\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/mariu/dev/school/TDT4215/tdt4215-2022/project_example.py?line=191'>192</a>\u001b[0m mf_als \u001b[39m=\u001b[39m mf\u001b[39m.\u001b[39mExplicitMF(train, n_factors\u001b[39m=\u001b[39m\u001b[39m40\u001b[39m, \n\u001b[1;32m    <a href='file:///Users/mariu/dev/school/TDT4215/tdt4215-2022/project_example.py?line=192'>193</a>\u001b[0m                        user_reg\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m, item_reg\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/mariu/dev/school/TDT4215/tdt4215-2022/project_example.py?line=193'>194</a>\u001b[0m iter_array \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m25\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m100\u001b[39m]\n\u001b[0;32m--> <a href='file:///Users/mariu/dev/school/TDT4215/tdt4215-2022/project_example.py?line=194'>195</a>\u001b[0m mf_als\u001b[39m.\u001b[39;49mcalculate_learning_curve(iter_array, test)\n\u001b[1;32m    <a href='file:///Users/mariu/dev/school/TDT4215/tdt4215-2022/project_example.py?line=195'>196</a>\u001b[0m \u001b[39m# plot out learning curves\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/mariu/dev/school/TDT4215/tdt4215-2022/project_example.py?line=196'>197</a>\u001b[0m plot_learning_curve(iter_array, mf_als)\n",
      "File \u001b[0;32m~/dev/school/TDT4215/tdt4215-2022/ExplicitMF.py:119\u001b[0m, in \u001b[0;36mExplicitMF.calculate_learning_curve\u001b[0;34m(self, iter_array, test)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/mariu/dev/school/TDT4215/tdt4215-2022/ExplicitMF.py?line=115'>116</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/mariu/dev/school/TDT4215/tdt4215-2022/ExplicitMF.py?line=116'>117</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpartial_train(n_iter \u001b[39m-\u001b[39m iter_diff)\n\u001b[0;32m--> <a href='file:///Users/mariu/dev/school/TDT4215/tdt4215-2022/ExplicitMF.py?line=118'>119</a>\u001b[0m predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict()\n\u001b[1;32m    <a href='file:///Users/mariu/dev/school/TDT4215/tdt4215-2022/ExplicitMF.py?line=120'>121</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_mse \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_mse(predictions, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mratings)]\n\u001b[1;32m    <a href='file:///Users/mariu/dev/school/TDT4215/tdt4215-2022/ExplicitMF.py?line=121'>122</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_mse \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_mse(predictions, test)]\n",
      "File \u001b[0;32m~/dev/school/TDT4215/tdt4215-2022/ExplicitMF.py:88\u001b[0m, in \u001b[0;36mExplicitMF.predict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/mariu/dev/school/TDT4215/tdt4215-2022/ExplicitMF.py?line=85'>86</a>\u001b[0m \u001b[39mfor\u001b[39;00m u \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_vecs\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[1;32m     <a href='file:///Users/mariu/dev/school/TDT4215/tdt4215-2022/ExplicitMF.py?line=86'>87</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_vecs\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m---> <a href='file:///Users/mariu/dev/school/TDT4215/tdt4215-2022/ExplicitMF.py?line=87'>88</a>\u001b[0m         predictions[u,i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muser_vecs[u,:]\u001b[39m.\u001b[39;49mdot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitem_vecs[i, :]\u001b[39m.\u001b[39;49mT)\n\u001b[1;32m     <a href='file:///Users/mariu/dev/school/TDT4215/tdt4215-2022/ExplicitMF.py?line=89'>90</a>\u001b[0m \u001b[39mreturn\u001b[39;00m predictions\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"\\nRecommendation based on MF...\")\n",
    "pe.collaborative_filtering(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fbaf27-6602-4433-a3b4-0de1ae4ce609",
   "metadata": {},
   "source": [
    "### 5.2 Content-based filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bde14eb-2cf5-4682-863a-14c5ccc15481",
   "metadata": {},
   "source": [
    "Content-based recommendations are another popular used recommendation methods. They make recommendations by analysing the content of textual information and finding regularities in the content.\n",
    "In this example, we adopt TF-IDF (Term Frequency ‚Äì Inverse Document Frequency) for feature selection and Cosine similarity to find the most similar items with user clicking before.\n",
    "\n",
    "TF-IDF can be implemented with help of *scikit-learn*, a useful Python package for machine learning tasks. Specifically, *TfidfVectorizer* converts a collection of raw documents to a matrix of TF-IDF features. We then use cosine similarity to measure the similarity of two items.\n",
    "\n",
    "The recommendation results can be a ranked list of all candidate items according to the cosine similarities with the last clicking item. The evaluation is according to *Recall@k* and *ARHR@k*. The detailed definition of Recall and ARHR is also provided in the next section. In the output that follows, we calculate these metrics for recommendation lists of k=20 articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "141ff590-8a3e-4df1-86b8-35e06c2a9dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendation based on content-based method...\n",
      "Dimension of feature vector: (20393, 169)\n",
      "Similarity Matrix:\n",
      "[[1.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.14058365]\n",
      " [0.         0.         0.14058365 1.        ]]\n",
      "                                           userId        time  tid  \\\n",
      "0     cx:10k2wzm1b3jsk2y5ym1utnjo97:2kefzqaxe9jx7  1483293374    1   \n",
      "194   cx:10k2wzm1b3jsk2y5ym1utnjo97:2kefzqaxe9jx7  1483293397    2   \n",
      "220   cx:10k2wzm1b3jsk2y5ym1utnjo97:2kefzqaxe9jx7  1483293408    3   \n",
      "366   cx:10k2wzm1b3jsk2y5ym1utnjo97:2kefzqaxe9jx7  1483293422    4   \n",
      "514   cx:10k2wzm1b3jsk2y5ym1utnjo97:2kefzqaxe9jx7  1483293441    5   \n",
      "822   cx:10k2wzm1b3jsk2y5ym1utnjo97:2kefzqaxe9jx7  1483293500    6   \n",
      "1033  cx:10k2wzm1b3jsk2y5ym1utnjo97:2kefzqaxe9jx7  1483303959    7   \n",
      "1136  cx:10k2wzm1b3jsk2y5ym1utnjo97:2kefzqaxe9jx7  1483303964    8   \n",
      "1349  cx:10k2wzm1b3jsk2y5ym1utnjo97:2kefzqaxe9jx7  1483304044    9   \n",
      "1430  cx:10k2wzm1b3jsk2y5ym1utnjo97:2kefzqaxe9jx7  1483306828   10   \n",
      "1583  cx:10k2wzm1b3jsk2y5ym1utnjo97:2kefzqaxe9jx7  1483417209   11   \n",
      "1770  cx:10k2wzm1b3jsk2y5ym1utnjo97:2kefzqaxe9jx7  1483454187   12   \n",
      "2094  cx:10k2wzm1b3jsk2y5ym1utnjo97:2kefzqaxe9jx7  1483532935   13   \n",
      "2155  cx:10k2wzm1b3jsk2y5ym1utnjo97:2kefzqaxe9jx7  1483536131   14   \n",
      "2273  cx:10k2wzm1b3jsk2y5ym1utnjo97:2kefzqaxe9jx7  1483557015   15   \n",
      "2854  cx:10k2wzm1b3jsk2y5ym1utnjo97:2kefzqaxe9jx7  1483568272   16   \n",
      "3109  cx:10k2wzm1b3jsk2y5ym1utnjo97:2kefzqaxe9jx7  1483568345   17   \n",
      "3467  cx:10k2wzm1b3jsk2y5ym1utnjo97:2kefzqaxe9jx7  1483568356   18   \n",
      "4105  cx:10k2wzm1b3jsk2y5ym1utnjo97:2kefzqaxe9jx7  1483568388   19   \n",
      "4160  cx:10k2wzm1b3jsk2y5ym1utnjo97:2kefzqaxe9jx7  1483568458   20   \n",
      "\n",
      "                                                  title  \\\n",
      "0     Norges landslagssjef ville ha russisk leder ut...   \n",
      "194   Arsenal-spissens spektakul√¶re scoring hylles: ...   \n",
      "220   Frykter at gode fiskeplasser g√•r tapt til Salm...   \n",
      "366                          Iiiiiiiiiskaldt nytt√•rsbad   \n",
      "514                                 Her laver sn√∏en ned   \n",
      "822      I morgen blir det kaffe og boller p√• stasjonen   \n",
      "1033                Kvinne omkommet etter ulykke p√• E39   \n",
      "1136  To av tre Northug-br√∏dre tilbake for fullt: Ti...   \n",
      "1349  Hopplegenden ble r√∏rt av Tandes triumf: ‚Äì Like...   \n",
      "1430                       Kvinne omkom i ulykke p√• E39   \n",
      "1583         Eriksson kan m√•tte tilbakebetale etterl√∏nn   \n",
      "1770               - Jeg fikk svingt unna i siste liten   \n",
      "2094            Reagerer sterkt p√• usikkerhet om campus   \n",
      "2155            Nedtur for Harsem: - Aldri v√¶rt s√• stiv   \n",
      "2273                                  - Dette er pinlig   \n",
      "2854  Ordf√∏rer g√•r i rette med kommunaldirekt√∏r om N...   \n",
      "3109               Tatt i 120 km/t i Strindheimtunnelen   \n",
      "3467  Da han kom tilbake fra alpinbakken s√• bilen sl...   \n",
      "4105     ¬´Northug-kopien gj√∏r ting Petter aldri klarte¬ª   \n",
      "4160      Iversen varslet legen tre dager f√∏r kollapsen   \n",
      "\n",
      "                          category  \n",
      "0      ['100sport', 'vintersport']  \n",
      "194                                 \n",
      "220           ['pluss', 'nyheter']  \n",
      "366       ['nyheter', 'trondheim']  \n",
      "514    ['nyheter', 'sortrondelag']  \n",
      "822    ['nyheter', 'sortrondelag']  \n",
      "1033                                \n",
      "1136   ['100sport', 'vintersport']  \n",
      "1349   ['100sport', 'vintersport']  \n",
      "1430    ['nyheter', 'moreromsdal']  \n",
      "1583                                \n",
      "1770  ['nyheter', 'nordtrondelag']  \n",
      "2094          ['pluss', 'nyheter']  \n",
      "2155                                \n",
      "2273                                \n",
      "2854                                \n",
      "3109      ['nyheter', 'trondheim']  \n",
      "3467          ['pluss', 'nyheter']  \n",
      "4105                                \n",
      "4160   ['100sport', 'vintersport']  \n",
      "Recall@20 is 0.0070\n",
      "ARHR@20 is 0.0006\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRecommendation based on content-based method...\")\n",
    "pe.content_recommendation(df, k=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f64329-20ab-480a-97d6-0f110c4ae2c5",
   "metadata": {},
   "source": [
    "## 6. Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36615807-4426-47d8-9f51-10a0d46e9379",
   "metadata": {},
   "source": [
    "Evaluation of recommendation system performance is never an easy task. Your job is somewhat simplified by the nature of data you are provided with. In this section we list some of the most commonly used metrics for offline evaluation: recall, CTR, ARHR, and MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b65a4b-7fd3-4fb3-a084-34134daf64cb",
   "metadata": {},
   "source": [
    "### 6.1 Recall (Hit Rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c44f9c7-9c1c-4f72-88cf-d3cf69ec8f11",
   "metadata": {},
   "source": [
    "Recall is used to measure the fraction of positive instances that are correctly predicted, which can be defined as:\n",
    "\n",
    "$$\n",
    "  Recall = \\frac{tp}{tp+fn}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $tp$ stands for true positive - the number of positive instances that are correctly predicted, and\n",
    "- $fn$ is false negative - the number of mispredicted negative instances.\n",
    "\n",
    "Also of interest are:\n",
    "- true negative $tn$, the number of negative instances that are correctly predicted, and\n",
    "- false positive $fp$, the number of mispredicted positive instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cddab6-751f-49cd-a205-6f6f4ec242fc",
   "metadata": {},
   "source": [
    "### 6.2 CTR (Click Through Rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b7acb0-6488-45ef-aa70-c6c53a7895f2",
   "metadata": {},
   "source": [
    "Click through rate is the number of recommendations produced by a participating system that are clicked by users normalised by the total number of requests for recommendations that were sent to that\n",
    "system.\n",
    "\n",
    "**Example**: Participant \"rocking recommendations\" receives 100,000 recommendation requests. The system manages to provide valid, in-time suggestions in 95,000 cases. Users click on 4,500 suggestions.\n",
    "\n",
    "We compute a CTR of 4,500 / 100,000 = 4.5%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0cce0e-ba02-4e7c-be2c-f71ef16e3214",
   "metadata": {},
   "source": [
    "### 6.3 ARHR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c8812f-7a7a-4dda-a1c4-fb52479bbc9a",
   "metadata": {},
   "source": [
    "The third measure that is commonly used, is the average reciprocal hit rate (ARHR). This measure is designed for implicit feedback data sets, in which each value of $r_{uj} \\in \\{0,1\\}$. Therefore, a value of $r_{uj}=1$ represents a \"hit\" where a customer has bought or clicked on an item, and value $r_{uj}=0$ corresponds to a situation where a customer has not bought or clicked on an item. In this implicit feedback setting, missing values in the ratings matrix are assumed to be 0. Then, the ARHR metric for the user $u$ is defined as:\n",
    "\n",
    "$$\n",
    "  ARHR(u) = \\sum_{j \\in I_u} \\frac{r_{uj}}{v_j}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $v$ is the rank of item $j$ in the recommended list, and\n",
    "- $I_u$ represents the set of items rated by user $u$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753b6895-b40e-4ee8-acc3-ef263b46b936",
   "metadata": {},
   "source": [
    "### 6.4 MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95676e8-e8f8-4fb2-8a73-7f03b06721c3",
   "metadata": {},
   "source": [
    "Mean Squared Error (MSE) is a widely used predictive accuracy metric. It takes the sum of the squared difference between the user's rating/score and the predicted rating/score and divides it by the number of items considered.\n",
    "\n",
    "$$\n",
    "  MSE = \\frac{1}{|I|} \\sum_{b \\in I_u} (r(b) - \\hat{r}(b))^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $I$ represents the items in the test dataset,\n",
    "- $r$ represents the observed value, and\n",
    "- $\\hat{r}$ represents the predicted value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7946df-bfea-47fc-ade8-39070806337f",
   "metadata": {},
   "source": [
    "## 7. Links that you may find useful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a9b594-291b-4bdb-8eef-2494412477c1",
   "metadata": {},
   "source": [
    "- LensKit library: https://lenskit.org/\n",
    "- Machine Learning in Python - scikit-learn: http://scikit-learn.org/stable/\n",
    "- Natural Language Toolkit: http://www.nltk.org/\n",
    "- Numpy ‚Äì Scientific computing with Python: http://www.numpy.org/\n",
    "- Pandas ‚Äì Python Data Analysis Library: https://pandas.pydata.org\n",
    "\n",
    "Also feel free to look for inspiration either in the textbooks we use (like [one by C. Aggarwal](https://link.springer.com/book/10.1007/978-3-319-29659-3) or [RS Handbook](https://link.springer.com/book/10.1007/978-1-4899-7637-6)), more hands-on sources (like [*Practical RS*](https://www.manning.com/books/practical-recommender-systems)), or online. In any case, make sure to cite your sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d95eb9-3b7c-4a24-bfd7-76bc1c78302e",
   "metadata": {},
   "source": [
    "## 8. Group formation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382d7364-831a-407e-b4b8-ff096f853995",
   "metadata": {},
   "source": [
    "As stated previously, project will be done in groups of 2 to 4 students. You should try to form groups by yourselves. If you can't, send an email to Mateja before the deadline, and you'll be assigned to one.\n",
    "\n",
    "When you have formed a group, enter your names in the Google sheet linked on the Blackboard, in 'Group project' section. You will be contacted after the group formation deadline to confirm your formation and contact via your NTNU email address. If you would rather be contacted with other email address, send an email to Mateja or just put that other address in the spreadsheet.\n",
    "\n",
    "The deadline for the group formation is extended to the **9th of February, end of day (23:59)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e94a80-0db7-4034-9a63-b2a847668acd",
   "metadata": {},
   "source": [
    "## 9. Help with the project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643ce145-2d98-497c-a74f-b1e915d07584",
   "metadata": {},
   "source": [
    "The Q&A sessions will be held every other Monday at 10:00 in room R3, according to the course calendar on Blackboard. Obviously, this is subject to change at any moment depending on the spread of the infection.\n",
    "\n",
    "Outside the Q&A sessions, you can email Mateja about any questions you might have related to the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff662fc9-3d8a-407d-9ab9-847c4b07a910",
   "metadata": {},
   "source": [
    "## 10. Version history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71918653-d9ef-42f0-b4db-a5dcf4b0fdd7",
   "metadata": {},
   "source": [
    "**24th January** - Initial version\n",
    "\n",
    "**8th February** - Updated information about the extended deadline for project groups"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
